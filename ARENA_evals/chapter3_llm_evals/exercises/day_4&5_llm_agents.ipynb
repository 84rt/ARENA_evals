{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# !pip install wikipedia\n",
    "import wikipedia\n",
    "from wikipedia import WikipediaPage\n",
    "import openai\n",
    "from wikipedia import DisambiguationError, PageError\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message_tool_call import (\n",
    "    ChatCompletionMessageToolCall,\n",
    ")\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "# !pip install anthropic\n",
    "from anthropic import Anthropic\n",
    "from typing import Literal, Optional, Dict, List, Any\n",
    "from abc import abstractmethod\n",
    "import math\n",
    "import re\n",
    "\n",
    "#Make sure exercises are in the path\n",
    "# exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "# section_dir = (exercises_dir / \"part4_llm_agent_evals\").resolve()\n",
    "# if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "# os.chdir(exercises_dir)\n",
    "\n",
    "from utils import import_json, save_json, retry_with_exponential_backoff, pretty_print_questions, load_jsonl, omit\n",
    "from utils import countrylist\n",
    "from utils import evaluate_expression, apply_user_format, apply_assistant_format, establish_client_anthropic, establish_client_OpenAI, retry_with_exponential_backoff\n",
    "import part4_llm_agents.tests as tests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = api_key\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple Arithemtic Agent\n",
    "We are going to implement 4 things:\n",
    "1. `ArithemticTask` class for handling the generation of arithemtic problems and their solutions\n",
    "2. `CalcualteTool` a tool the LLM can use to solve the task\n",
    "3. `ArithmeticAgent` class for handling the LLM API, calculations, and keeping track of overall progress\n",
    "4. `AgentLoop` function that defines the interaction loop between the task and the LLM (agent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 + 15 = 25.0\n",
      "10 - 15 = -5.0\n",
      "10 * 15 = 150.0\n",
      "10 / 15 = 0.6666666666666666\n",
      "10 % 15 = 10.0\n",
      "10 // 15 = 0.0\n"
     ]
    }
   ],
   "source": [
    "class ArithmeticTask:\n",
    "    def __init__(self, num1: int | float, num2: int | float):\n",
    "        self.num1 = num1\n",
    "        self.num2 = num2\n",
    "        self.operations: List[str] = [\"+\", \"-\", \"*\", \"/\", \"%\", \"//\"]\n",
    "        self.correct_answers: Dict[str, float] = self._generate_answers()\n",
    "        self.is_solved: Dict[str, bool] = {expr: False for expr in self.correct_answers}\n",
    "        self.current_task_number = 0\n",
    "\n",
    "    def _generate_answers(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Generates a dictionary the correct answers for all possible tasks\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: A dictionary with the expression as key and the correct answer as value\n",
    "        \"\"\"\n",
    "        answ = {}\n",
    "        for op in self.operations:\n",
    "                answ[f\"{self.num1} {op} {self.num2}\"] = evaluate_expression(f\"{self.num1} {op} {self.num2}\")\n",
    "        return answ\n",
    "\n",
    "    @property\n",
    "    def get_current_task(self) -> str:\n",
    "        \"\"\"\n",
    "        Gets the current task for the agent\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the current task\n",
    "        \"\"\"\n",
    "        return f\"{str(self.num1)} {self.operations[self.current_task_number]} {str(self.num2)}\"\n",
    "\n",
    "    @property\n",
    "    def instruction(self) -> str:\n",
    "        \"\"\"\n",
    "        Gets a string containing instructions for the current task for the agent. (This will be fed to the agent as a user prompt)\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the instructions for the current task\n",
    "        \"\"\"\n",
    "        return f\"Calculate the result of the following expression: {str(self.num1)} {self.operations[self.current_task_number]} {str(self.num2)}. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\"\n",
    "\n",
    "    def check_solved(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if all tasks have been solved\n",
    "\n",
    "        Returns:\n",
    "            bool: True if all tasks have been solved, False otherwise\n",
    "        \"\"\"\n",
    "        return all(self.is_solved.values())\n",
    "\n",
    "    def check_answer(self, model_answer: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the model's answer is correct\n",
    "\n",
    "        Args:\n",
    "            model_answer (str): The model's answer\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the model's answer is correct, False otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        correct_answer = self.correct_answers[self.get_current_task]\n",
    "        return math.isclose(\n",
    "            float(model_answer), correct_answer, rel_tol=1e-5, abs_tol=1e-8\n",
    "        )\n",
    "\n",
    "    def update_current_task(self):\n",
    "        \"\"\"\n",
    "        Sets is_solved for the current task to True and increments self.current_task_number by one\n",
    "        \"\"\"\n",
    "        self.is_solved[self.get_current_task] = True\n",
    "        self.current_task_number = (self.current_task_number + 1) % len(self.operations)\n",
    "\n",
    "\n",
    "\n",
    "x = ArithmeticTask(10, 15)\n",
    "for problem, answer in x.correct_answers.items():\n",
    "    print(f\"{problem} = {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_execute_valid_expressions passed\n",
      "test_description_property passed\n",
      "All CalculateTool tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Calculate Tool\n",
    "\n",
    "class CalculateTool():\n",
    "    name = \"calculate\"\n",
    "\n",
    "    @staticmethod\n",
    "    def execute(expression: str, task: Any = None) -> str:\n",
    "        \"\"\"\n",
    "        Evaluates the string expression in Python using `evaluate_expression()` and returns the result as a string\n",
    "\n",
    "        Args:\n",
    "            expression (str): The arithmetic expression to evaluate\n",
    "            task (Any): Not used in this function\n",
    "\n",
    "        Returns:\n",
    "            str: The result of the arithmetical expression as a string\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return str(evaluate_expression(expression))\n",
    "        except (SyntaxError, NameError, ZeroDivisionError) as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    @property\n",
    "    def description(self):\n",
    "        \"\"\"\n",
    "        Provides the description of the tool\n",
    "\n",
    "        Returns:\n",
    "            dict: The description of the tool\n",
    "        \"\"\"\n",
    "\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": 'Calculates the result of an arithmetic expression. For example, you could provide an input in the form \"2+3\" and the function would return 5. Or you could provide an expression like \"10/3\" and the function would return 3.3333333333333335.',\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The arithmetic expression that you want to be evaluated.\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    \n",
    "tests.run_calculate_tool_tests(CalculateTool)\n",
    "\n",
    "Calculator = CalculateTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[ChatCompletionMessageToolCall(id='call_MHvRe28RFl06hX8r2UYmGYap', function=Function(arguments='{\"expression\":\"2+3\"}', name='calculate'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Calculate 2+3\"}]\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=[Calculator.description],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tool_call_format(tool_call: ChatCompletionMessageToolCall, content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Formats the response of a tool call to be returned to the model.\n",
    "    Args:\n",
    "        - tool_call (ChatCompletionMessageToolCall) : The tool call object\n",
    "        - content (str) : This is the tool response (i.e. results from executing the tool)\n",
    "\n",
    "    Returns:\n",
    "        - dict : The formatted tool response to be returned to the model\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": content, # e.g. \"5\"\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"name\": tool_call.function.name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precise result of \\( \\frac{5}{3} \\) is approximately 1.6666666666666667.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Calculate 5/3. Be precise.\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=[Calculator.description],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "messages.extend(\n",
    "    [\n",
    "        response.choices[0].message,\n",
    "        apply_tool_call_format(\n",
    "            response.choices[0].message.tool_calls[0],\n",
    "            Calculator.execute(\n",
    "                json.loads(\n",
    "                    response.choices[0].message.tool_calls[0].function.arguments\n",
    "                )[\"expression\"]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_to_tool_calls = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=[Calculator.description],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "print(response_to_tool_calls.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        task: Any = None,\n",
    "        model: Literal[\"gpt-4o-mini\"] = \"gpt-4o-mini\",\n",
    "        tools: Optional[List[Any]] = None,\n",
    "        chat_history: Optional[List[dict]] = None,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.task = task\n",
    "        self.tools = tools\n",
    "        self.client = OpenAI()\n",
    "        self.chat_history = chat_history if chat_history else []\n",
    "\n",
    "    @retry_with_exponential_backoff\n",
    "    def get_response(self, use_tool: bool = True) -> ChatCompletionMessage:\n",
    "        \"\"\"\n",
    "        Get the response from the model via an API call, with the option of tool calling.\n",
    "\n",
    "        Args:\n",
    "            use_tool (bool): Whether to use tool calling or not\n",
    "\n",
    "        Returns:\n",
    "            ChatCompletionMessage: The response from the model\n",
    "        \"\"\"\n",
    "\n",
    "        return response.choices[0].message\n",
    "\n",
    "    def execute_tool_calls(self, message: ChatCompletionMessage) -> List[str]:\n",
    "        \"\"\"\n",
    "        Execute the tool calls in the message and return a list of tool_responses.\n",
    "\n",
    "        Args:\n",
    "            message (ChatCompletionMessage): The message containing the tool calls\n",
    "\n",
    "        Returns:\n",
    "            List[str]: A list of tool responses (as strings, we'll format them correctly in run())\n",
    "        \"\"\"\n",
    "\n",
    "        return tool_responses\n",
    "\n",
    "    def run(self, with_tool: bool = True) -> ChatCompletionMessage:\n",
    "        \"\"\"\n",
    "        Default implementation of run method.\n",
    "        This can be overridden in subclasses for specific behavior.\n",
    "\n",
    "        Args:\n",
    "            with_tool (bool): Whether to use tool calling or not\n",
    "\n",
    "        Returns:\n",
    "            str: The response from the model\n",
    "        \"\"\"\n",
    "        print(f\"Running SimpleAgent...\")\n",
    "        instruction = self.task.current_task_instruction\n",
    "        self.chat_history.append(apply_user_format(instruction))\n",
    "        response = self.get_response(use_tool=with_tool)\n",
    "        return response\n",
    "\n",
    "tests.test_execute_tool_calls(SimpleAgent, CalculateTool, ArithmeticTask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
